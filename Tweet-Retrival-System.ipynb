{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import nltk\n",
    "import re\n",
    "from time import sleep\n",
    "import io\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import itertools\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tweet_length = 10\n",
    "\n",
    "\n",
    "topics_en = [\n",
    "    \"We should stop subsidizing meat\",\n",
    "    \"We should subsidize green nutrition\",\n",
    "    \"We have to increase production of meat\",\n",
    "    \"We should exempt meat production from carbon taxes\",\n",
    "    \"We should add a carbon tax to food production\",\n",
    "    \"Meat alternatives should be encouraged\",\n",
    "    \"Plant based should be encouraged\",\n",
    "    \"Meat alternatives should be invested in\",\n",
    "    \"Plant based should be invested in\",\n",
    "    \"Meat alternatives should be subsidized\",\n",
    "    \"Plant based should be subsidized\",\n",
    "    \"We should introduce meatless mondays\",\n",
    "    \"Vegetarian and vegan diets should be encouraged\",\n",
    "    \"Vegetarian and vegan diets should be discouraged\",\n",
    "    \"We should subsidize fruits and vegetables\",\n",
    "    \"We should encourage more fruits and vegetable consumption\",\n",
    "    \"We should discourage fruits and vegetable consumption\",\n",
    "] \n",
    "\n",
    "topics_da = [\n",
    "    \"Vi bør stoppe med at subsidiere kød\",\n",
    "    \"Vi bør subsidiere grøn ernæring\",\n",
    "    \"Vi skal øge produktionen af kød\",\n",
    "    \"Vi bør fritage kød produktion fra co2 afgifter\",\n",
    "    \"Vi bør tilføje en co2 afgift til fødevare produktionen\",\n",
    "    \"Alternativer til kød bør fremmes og støttes\",\n",
    "    \"Plantebaseret bør fremmes og støttes\",\n",
    "    \"Der bør investeres i kødalternativer\",\n",
    "    \"Der bør investeres i plantebaseret\",\n",
    "    \"Alternativer til kød bør subsidieres\",\n",
    "    \"Plantebaseret bør subsidieres\",\n",
    "    \"Der bør opfordres til vegetarisk og vegansk kost\",\n",
    "    \"Vegetarisk og vegansk kost bør frarådes\",\n",
    "    \"Vi bør subsidiere frugt og grøntsager\",\n",
    "    \"Vi bør fremme forbruget af frugt og grøntsager\",\n",
    "    \"Vi bør fraråde forbrug af frugt og grøntsager\"\n",
    "]\n",
    "\n",
    "tweet_df = pd.read_csv('scraped_tweets_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre(string, lang):\n",
    "    stemmer = SnowballStemmer('english' if lang == 'en' else 'danish')\n",
    "    stops = set(stopwords.words('english' if lang == 'en' else 'danish'))\n",
    "    \n",
    "    words = word_tokenize(re.sub('[^a-zA-Z]', ' ', string.lower().strip()))                        \n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    return ' '.join([stemmer.stem(w) for w in meaningful_words])\n",
    "\n",
    "def filter_tweets(df):\n",
    "    return df[df.tweet.str.split().str.len() > min_tweet_length]\n",
    "\n",
    "def score_tfidf(df, topic, lang):\n",
    "    df = filter_tweets(df).copy()\n",
    "    df['score'] = [0]*len(df) \n",
    "\n",
    "    corpus = list(map(lambda x: pre(x, lang), df[df.lang == lang].tweet.values))\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_mtx = vectorizer.fit_transform(corpus)\n",
    "    topic_mtx = vectorizer.transform([pre(topic, lang)])\n",
    "\n",
    "    cos_score = cosine_similarity(tfidf_mtx, topic_mtx)\n",
    "\n",
    "    df.loc[df.lang == lang, ['score']] = cos_score\n",
    "    return df\n",
    "\n",
    "scored = score_tfidf(tweet_df, topics_en[9], 'en')\n",
    "\n",
    "top = scored.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_scores(df):\n",
    "    top = df.sort_values(by=['score'], ascending=False)\n",
    "    i = 0\n",
    "    for r in top.head(i+10).iloc[i:].iloc:\n",
    "        print('Topic:', r.topic, 'Tweet:', r.tweet, 'Score:', r.score)\n",
    "        print('='*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qa_model_score(df, topics, dot_score = True):    \n",
    "    df = df.copy()\n",
    "    df['score'] = [0]*len(df) \n",
    "    \n",
    "    #Load the model\n",
    "    model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "    docs = df.tweet.values\n",
    "    doc_emb = model.encode(docs)\n",
    "\n",
    "    \n",
    "    score_dfs = [] \n",
    "    for topic in topics:\n",
    "    \n",
    "        df['score'] = [0]*len(df) \n",
    "        df['topic'] = [topic]*len(df)\n",
    "    \n",
    "        #Encode query and documents\n",
    "        query_emb = model.encode(topic)\n",
    "        \n",
    "        if dot_score:\n",
    "            #Compute dot score between query and all document embeddings\n",
    "            scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "        else:\n",
    "            scores = cosine_similarity(query_emb, doc_emb)[0].tolist()\n",
    "            \n",
    "        #Combine docs & scores\n",
    "        #doc_score_pairs = list(zip(docs, scores))\n",
    "        df['score'] = scores\n",
    "        score_dfs.append(df.copy())\n",
    "\n",
    "        #Sort by decreasing score\n",
    "        #doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "    return score_dfs\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = qa_model_score(tweet_df, topics_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_df_scores(scores[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tweet_df[tweet_df.].sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['topic'] = np.random.choice(topics_en, len(sample))\n",
    "sample['score'] = [0]*len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_top_samples(dfs, samples, top = 100):\n",
    "    top_dfs = []\n",
    "    for df in dfs:\n",
    "        top_dfs.append(df.sort_values(by=['score'], ascending=False)[:top])\n",
    "    return pd.concat(top_dfs).sample(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.concat([sample, random_top_samples(scores, 25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
