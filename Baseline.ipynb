{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mah/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811757556/work/c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline\n",
    "import tweepy\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.data import Sentence\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import nltk\n",
    "from utils import numerical_df\n",
    "from baselines import xgboost_baseline, majority_class_baseline, random_class_baseline, ibm_baseline, bert_baseline, bm25_baseline, qa_model_baseline\n",
    "from sklearn.metrics import f1_score as f1, precision_score as ps, recall_score as rs\n",
    "from sklearn.model_selection import KFold\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arg = numerical_df(pd.read_csv('./mkturk/argumentative.csv')).drop(columns = ['Unnamed: 0'])\n",
    "df_claim = numerical_df(pd.read_csv('./mkturk/claims.csv'))\n",
    "## Remove empty strings\n",
    "#df = df[df.tweet != '']\n",
    "#df = df[df.tweet.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 1271)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arg.loc[df_arg.argumentative > 0.49, 'argumentative'] = 1\n",
    "df_arg.loc[df_arg.argumentative < 0.5, 'argumentative'] = 0\n",
    "\n",
    "#df_claim.loc[df_claim.argumentative > 0.49, 'argumentative'] = 1\n",
    "#df_claim.loc[df_claim.argumentative < 0.5, 'argumentative'] = 0\n",
    "\n",
    "df_claim.loc[df_claim.claim > 0.49, 'claim'] = 1\n",
    "df_claim.loc[df_claim.claim < 0.5, 'claim'] = 0\n",
    "\n",
    "\n",
    "\n",
    "len(df_arg), len(df_claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_classes = ['argumentative', 'claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_35f5db0e_d07c_11ec_82ae_e37dd234f2a9\" ><caption>Majority class results with 10 fold split</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Task</th>        <th class=\"col_heading level0 col1\" >F1</th>        <th class=\"col_heading level0 col2\" >Precision</th>        <th class=\"col_heading level0 col3\" >Recall</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_35f5db0e_d07c_11ec_82ae_e37dd234f2a9level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_35f5db0e_d07c_11ec_82ae_e37dd234f2a9row0_col0\" class=\"data row0 col0\" >argumentative</td>\n",
       "                        <td id=\"T_35f5db0e_d07c_11ec_82ae_e37dd234f2a9row0_col1\" class=\"data row0 col1\" >0.6499999999999999</td>\n",
       "                        <td id=\"T_35f5db0e_d07c_11ec_82ae_e37dd234f2a9row0_col2\" class=\"data row0 col2\" >0.6499999999999999</td>\n",
       "                        <td id=\"T_35f5db0e_d07c_11ec_82ae_e37dd234f2a9row0_col3\" class=\"data row0 col3\" >0.6499999999999999</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f804ee83700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_35fa1110_d07c_11ec_82ae_e37dd234f2a9\" ><caption>Majority class results with 10 fold split</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Task</th>        <th class=\"col_heading level0 col1\" >F1</th>        <th class=\"col_heading level0 col2\" >Precision</th>        <th class=\"col_heading level0 col3\" >Recall</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_35fa1110_d07c_11ec_82ae_e37dd234f2a9level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_35fa1110_d07c_11ec_82ae_e37dd234f2a9row0_col0\" class=\"data row0 col0\" >claim</td>\n",
       "                        <td id=\"T_35fa1110_d07c_11ec_82ae_e37dd234f2a9row0_col1\" class=\"data row0 col1\" >0.7313789455122552</td>\n",
       "                        <td id=\"T_35fa1110_d07c_11ec_82ae_e37dd234f2a9row0_col2\" class=\"data row0 col2\" >0.7313789455122554</td>\n",
       "                        <td id=\"T_35fa1110_d07c_11ec_82ae_e37dd234f2a9row0_col3\" class=\"data row0 col3\" >0.7313789455122554</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8030344d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(majority_class_baseline(df_arg, ['argumentative']))\n",
    "display(majority_class_baseline(df_claim[df_claim.argumentative >= 0.5], ['claim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_4086419e_d07c_11ec_82ae_e37dd234f2a9\" ><caption>Random class results with 10 fold split using weighted approach</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Task</th>        <th class=\"col_heading level0 col1\" >F1</th>        <th class=\"col_heading level0 col2\" >Precision</th>        <th class=\"col_heading level0 col3\" >Recall</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4086419e_d07c_11ec_82ae_e37dd234f2a9level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_4086419e_d07c_11ec_82ae_e37dd234f2a9row0_col0\" class=\"data row0 col0\" >argumentative</td>\n",
       "                        <td id=\"T_4086419e_d07c_11ec_82ae_e37dd234f2a9row0_col1\" class=\"data row0 col1\" >0.4916666666666667</td>\n",
       "                        <td id=\"T_4086419e_d07c_11ec_82ae_e37dd234f2a9row0_col2\" class=\"data row0 col2\" >0.4916666666666667</td>\n",
       "                        <td id=\"T_4086419e_d07c_11ec_82ae_e37dd234f2a9row0_col3\" class=\"data row0 col3\" >0.4916666666666667</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f804ee83700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_408ab5c6_d07c_11ec_82ae_e37dd234f2a9\" ><caption>Random class results with 10 fold split using weighted approach</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Task</th>        <th class=\"col_heading level0 col1\" >F1</th>        <th class=\"col_heading level0 col2\" >Precision</th>        <th class=\"col_heading level0 col3\" >Recall</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_408ab5c6_d07c_11ec_82ae_e37dd234f2a9level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_408ab5c6_d07c_11ec_82ae_e37dd234f2a9row0_col0\" class=\"data row0 col0\" >claim</td>\n",
       "                        <td id=\"T_408ab5c6_d07c_11ec_82ae_e37dd234f2a9row0_col1\" class=\"data row0 col1\" >0.6078381237876919</td>\n",
       "                        <td id=\"T_408ab5c6_d07c_11ec_82ae_e37dd234f2a9row0_col2\" class=\"data row0 col2\" >0.6078381237876919</td>\n",
       "                        <td id=\"T_408ab5c6_d07c_11ec_82ae_e37dd234f2a9row0_col3\" class=\"data row0 col3\" >0.6078381237876919</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f803080bd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(random_class_baseline(df_arg, ['argumentative']))\n",
    "display(random_class_baseline(df_claim[df_claim.argumentative >= 0.5], ['claim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_baseline(df, tasks = current_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mah/.local/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claim</td>\n",
       "      <td>0.502356</td>\n",
       "      <td>0.502356</td>\n",
       "      <td>0.502356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Task        F1  Precision    Recall\n",
       "0  claim  0.502356   0.502356  0.502356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#bm25_baseline(df, current_classes)\n",
    "#display(bm25_baseline(df_arg, ['argumentative']))\n",
    "display(bm25_baseline(df_claim[df_claim.argumentative >= 0.5], ['claim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Didn't find file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/added_tokens.json. We won't load it.\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/vocab.txt\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/tokenizer.json\n",
      "loading file None\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/special_tokens_map.json\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring tweet topic pair \"We should pursue policies that promote sustainable foods\"\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Didn't find file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/added_tokens.json. We won't load it.\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/vocab.txt\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/tokenizer.json\n",
      "loading file None\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/special_tokens_map.json\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring tweet topic pair \"Meat alternatives should be encouraged\"\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Didn't find file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/added_tokens.json. We won't load it.\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/vocab.txt\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/tokenizer.json\n",
      "loading file None\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/special_tokens_map.json\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring tweet topic pair \"We should reduce the consumption of meat\"\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Didn't find file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/added_tokens.json. We won't load it.\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/vocab.txt\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/tokenizer.json\n",
      "loading file None\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/special_tokens_map.json\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring tweet topic pair \"Plant based food should be encouraged\"\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/\",\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "All the weights of BertModel were initialized from the model checkpoint at /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "Didn't find file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/added_tokens.json. We won't load it.\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/vocab.txt\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/tokenizer.json\n",
      "loading file None\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/special_tokens_map.json\n",
      "loading file /home/mah/.cache/torch/sentence_transformers/sentence-transformers_multi-qa-MiniLM-L6-cos-v1/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring tweet topic pair \"Vegan and vegetarian diets should be encouraged\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claim</td>\n",
       "      <td>0.647502</td>\n",
       "      <td>0.647502</td>\n",
       "      <td>0.647502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Task        F1  Precision    Recall\n",
       "0  claim  0.647502   0.647502  0.647502"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_model_baseline(df_claim[df_claim.argumentative >= 0.5].copy(), ['claim'], model_cutoff = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering results for claim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ClaimDetectionClient: 100%|██████████| 1061/1061 [00:15<00:00, 66.32it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_7d7e5a36_d07d_11ec_82ae_e37dd234f2a9\" ><caption>Results from using imbs project debater api for 0 shot evalutaion</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Tasks</th>        <th class=\"col_heading level0 col1\" >F1</th>        <th class=\"col_heading level0 col2\" >Precision</th>        <th class=\"col_heading level0 col3\" >Recall</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_7d7e5a36_d07d_11ec_82ae_e37dd234f2a9level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_7d7e5a36_d07d_11ec_82ae_e37dd234f2a9row0_col0\" class=\"data row0 col0\" >claim</td>\n",
       "                        <td id=\"T_7d7e5a36_d07d_11ec_82ae_e37dd234f2a9row0_col1\" class=\"data row0 col1\" >0.328302</td>\n",
       "                        <td id=\"T_7d7e5a36_d07d_11ec_82ae_e37dd234f2a9row0_col2\" class=\"data row0 col2\" >0.355102</td>\n",
       "                        <td id=\"T_7d7e5a36_d07d_11ec_82ae_e37dd234f2a9row0_col3\" class=\"data row0 col3\" >0.305263</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7f4ae62700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display(ibm_baseline(df_arg, ['argumentative']))\n",
    "display(ibm_baseline(df_claim[df_claim.argumentative >= 0.5], ['claim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/mah/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /home/mah/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /home/mah/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /home/mah/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /home/mah/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting out data, for fold 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b1ee2d7d4de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#bert_baseline(df, tasks=current_classes, use_topic=True, batch_size=5, epochs = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#display(ibm_baseline(df_arg, ['argumentative']))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_claim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_claim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margumentative\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'claim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_topic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/thesis/baselines.py\u001b[0m in \u001b[0;36mbert_baseline\u001b[0;34m(df, fold, model_name, tasks, use_topic, seed, batch_size, epochs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mfold_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Splitting out data, for fold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_num\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0mfold_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         self._validate_read_indexer(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             \u001b[0;31m# just raising\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m                 raise KeyError(\n\u001b[0m\u001b[1;32m   1655\u001b[0m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                     \u001b[0;34m\"is no longer supported, see \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
     ]
    }
   ],
   "source": [
    "#bert_baseline(df, tasks=current_classes, use_topic=True, batch_size=5, epochs = 1)\n",
    "#display(ibm_baseline(df_arg, ['argumentative']))\n",
    "display(bert_baseline(df_claim[df_claim.argumentative >= 0.5], tasks = ['claim'], use_topic=True, batch_size=5, epochs = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
