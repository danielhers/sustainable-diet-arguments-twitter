{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import xmltodict\n",
    "import json\n",
    "import pandas as pd\n",
    "import pyemoji\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_hits_in_production = False\n",
    "environments = {\n",
    "        \"production\": {\n",
    "            \"endpoint\": \"\",#\"https://mturk-requester.us-east-1.amazonaws.com\",\n",
    "            \"preview\": \"\",#\"https://www.mturk.com/mturk/preview\"\n",
    "        },\n",
    "        \"sandbox\": {\n",
    "            \"endpoint\": \"https://mturk-requester-sandbox.us-east-1.amazonaws.com\",\n",
    "            \"preview\": \"https://workersandbox.mturk.com/mturk/preview\"\n",
    "        },\n",
    "}\n",
    "mturk_environment = environments[\"production\"] if create_hits_in_production else environments[\"sandbox\"]\n",
    "\n",
    "client = boto3.client(\n",
    "    service_name='mturk',\n",
    "    region_name='us-east-1',\n",
    "    endpoint_url=mturk_environment['endpoint'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000.00\n"
     ]
    }
   ],
   "source": [
    "# This will return your current MTurk balance if you are connected to Production.\n",
    "# If you are connected to the Sandbox it will return $10,000.\n",
    "print(client.get_account_balance()['AvailableBalance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_mturk.csv')\n",
    "df_known = pd.read_csv('../full-sample-v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_layout = open('./argumentative.html', 'r').read()\n",
    "QUESTION_XML = \"\"\"<HTMLQuestion xmlns=\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/2011-11-11/HTMLQuestion.xsd\">\n",
    "        <HTMLContent><![CDATA[{}]]></HTMLContent>\n",
    "        <FrameHeight>650</FrameHeight>\n",
    "        </HTMLQuestion>\"\"\"\n",
    "question_xml = QUESTION_XML.format(html_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaskAttributes = {\n",
    "    'MaxAssignments': 5,                 \n",
    "    'LifetimeInSeconds': 60*120,            # How long the task will be available on the MTurk website (1 hour)\n",
    "    'AssignmentDurationInSeconds': 60*10, # How long Workers have to complete each item (10 minutes)\n",
    "    'Reward': '0.03',                     # The reward you will offer Workers for each response\n",
    "    'Title': 'Classify tweets',\n",
    "    'Keywords': 'classify, tweet',\n",
    "    'Description': 'Classify if tweets are argumentative'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating hit for tweet number 0\n",
      " Creating hit for tweet number 1\n",
      " Creating hit for tweet number 2\n",
      " Creating hit for tweet number 3\n",
      " Creating hit for tweet number 4\n",
      " Creating hit for tweet number 5\n",
      " Creating hit for tweet number 6\n",
      " Creating hit for tweet number 7\n",
      " Creating hit for tweet number 8\n",
      " Creating hit for tweet number 9\n",
      " Creating hit for tweet number 10\n",
      " Creating hit for tweet number 11\n",
      " Creating hit for tweet number 12\n",
      " Creating hit for tweet number 13\n",
      " Creating hit for tweet number 14\n",
      " Creating hit for tweet number 15\n",
      " Creating hit for tweet number 16\n",
      " Creating hit for tweet number 17\n",
      " Creating hit for tweet number 18\n",
      " Creating hit for tweet number 19\n",
      " Creating hit for tweet number 20\n",
      " Creating hit for tweet number 21\n",
      " Creating hit for tweet number 22\n",
      " Creating hit for tweet number 23\n",
      " Creating hit for tweet number 24\n",
      " Creating hit for tweet number 25\n",
      " Creating hit for tweet number 26\n",
      " Creating hit for tweet number 27\n",
      " Creating hit for tweet number 28\n",
      " Creating hit for tweet number 29\n",
      " Creating hit for tweet number 30\n",
      " Creating hit for tweet number 31\n",
      " Creating hit for tweet number 32\n",
      " Creating hit for tweet number 33\n",
      " Creating hit for tweet number 34\n",
      " Creating hit for tweet number 35\n",
      " Creating hit for tweet number 36\n",
      " Creating hit for tweet number 37\n",
      " Creating hit for tweet number 38\n",
      " Creating hit for tweet number 39\n",
      " Creating hit for tweet number 40\n",
      " Creating hit for tweet number 41\n",
      " Creating hit for tweet number 42\n",
      " Creating hit for tweet number 43\n",
      " Creating hit for tweet number 44\n",
      " Creating hit for tweet number 45\n",
      " Creating hit for tweet number 46\n",
      " Creating hit for tweet number 47\n",
      " Creating hit for tweet number 48\n",
      " Creating hit for tweet number 49\n",
      "You can view the HITs here:\n",
      "https://workersandbox.mturk.com/mturk/preview?groupId=370WPY2B8743IL7UE2HLRFCWQS53LU\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "hit_type_id = ''\n",
    "\n",
    "\n",
    "def encode_tweet(tweet):\n",
    "    return str(html.escape(tweet).replace('\\n', '<br/>').encode('ascii', 'xmlcharrefreplace')).replace(\"b'\", '')[:-1]\n",
    "\n",
    "df_set = pd.concat([df.drop(columns=['argumentative']), df_known]).sample(frac=1)\n",
    "\n",
    "\n",
    "for i, row in enumerate(df_set.head(50).to_dict('records')):\n",
    "    print('\\r', 'Creating hit for tweet number', i)\n",
    "    response = client.create_hit(\n",
    "        **TaskAttributes,\n",
    "        Question=question_xml.replace('${tweet}',encode_tweet(row['tweet'])),#.replace('${topic}', encode_tweet(row['topic']))\n",
    "    )\n",
    "    hit_type_id = response['HIT']['HITTypeId']\n",
    "    results.append({\n",
    "        'tweet': row['tweet'],\n",
    "        'hit_id': response['HIT']['HITId'],\n",
    "        'known_answer': row['argumentative']\n",
    "    })\n",
    "    \n",
    "print(\"You can view the HITs here:\")\n",
    "print(mturk_environment['preview'] + \"?groupId={}\".format(hit_type_id))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./active_hits.json', 'w') as fout:\n",
    "    json.dump(results, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = {\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "for item in results:\n",
    "    \n",
    "    # Get the status of the HIT\n",
    "    hit = client.get_hit(HITId=item['hit_id'])\n",
    "    item['status'] = hit['HIT']['HITStatus']\n",
    "\n",
    "    # Get a list of the Assignments that have been submitted by Workers\n",
    "    assignmentsList = client.list_assignments_for_hit(\n",
    "        HITId=item['hit_id'],\n",
    "        AssignmentStatuses=['Submitted', 'Approved'],\n",
    "        MaxResults=10\n",
    "    )\n",
    "\n",
    "    assignments = assignmentsList['Assignments']\n",
    "    item['assignments_submitted_count'] = len(assignments)\n",
    "\n",
    "    answers = []\n",
    "    for assignment in assignments:\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Retreive the attributes for each Assignment\n",
    "        worker_id = assignment['WorkerId']\n",
    "        assignment_id = assignment['AssignmentId']\n",
    "        \n",
    "        # Retrieve the value submitted by the Worker from the XML\n",
    "        answer_dict = xmltodict.parse(assignment['Answer'])\n",
    "        answer = answer_dict['QuestionFormAnswers']['Answer']['FreeText']\n",
    "        answer_dict['worker'] = worker_id\n",
    "        answer_dict['answer'] = answer\n",
    "        answers.append(answer_dict)\n",
    "        \n",
    "        \n",
    "        workser_work = {\n",
    "            \"answer\": answer,\n",
    "            \"known_answer\": item['known_answer'],\n",
    "            \"assignment_id\": assignment['AssignmentId'],\n",
    "        }\n",
    "        if worker_id in workers:\n",
    "            workers[worker_id].append(workser_work)\n",
    "        else:\n",
    "            workers[worker_id] = [workser_work]\n",
    "        \n",
    "        # Approve the Assignment (if it hasn't already been approved)\n",
    "        #if assignment['AssignmentStatus'] == 'Submitted':\n",
    "        #    client.approve_assignment(\n",
    "        #        AssignmentId=assignment_id,\n",
    "        #        OverrideRejection=False\n",
    "        #    )\n",
    "    \n",
    "    # Add the answers that have been retrieved for this item\n",
    "    item['answers'] = answers\n",
    "\n",
    "\n",
    "\n",
    "#print(json.dumps(results,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for worker in workers:\n",
    "    work = workers[worker]\n",
    "    num_known = 0\n",
    "    num_correct = 0\n",
    "    \n",
    "    for assign in work:\n",
    "        if not pd.isnull(assign['known_answer']):\n",
    "            num_known = num_known + 1\n",
    "            if assign['known_answer'] == '0' and assign['answer'] == 'not argumentative':\n",
    "                num_correct = num_correct + 1\n",
    "            if assign['known_answer'] == '1' and assign['answer'] == 'argumentative':\n",
    "                num_correct = num_correct + 1\n",
    "    if num_known > 4:\n",
    "        for assign in work:\n",
    "            if num_correct/num_known > 0.65:\n",
    "                client.approve_assignment(\n",
    "                    AssignmentId=assign['assignment_id'],\n",
    "                    OverrideRejection=False\n",
    "                )\n",
    "            else:\n",
    "                client.reject_assignment(\n",
    "                    AssignmentId=assign['assignment_id'],\n",
    "                    RequesterFeedback=\"You failed to achive at least 70% agreement with known annotations\"\n",
    "                )\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_known, num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
