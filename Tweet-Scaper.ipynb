{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import nltk\n",
    "import re\n",
    "from time import sleep\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no tweets will be found for a date older than one week.\n",
    "# https://docs.tweepy.org/en/stable/api.html#search-tweets\n",
    "\n",
    "\n",
    "# this one needs academic access to twitter apiu\n",
    "#https://docs.tweepy.org/en/stable/client.html#search-tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373db49",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Twitter stuff\n",
    "\n",
    "credentials_path = './credentials.json'\n",
    "\n",
    "with io.open(credentials_path) as f_in:\n",
    "    credentials = json.load(f_in)\n",
    "\n",
    "\n",
    "access_token = credentials[\"access_token\"]\n",
    "access_token_secret = credentials[\"access_token_secret\"]\n",
    "\n",
    "\n",
    "api_key = credentials[\"api_key\"]\n",
    "api_secret = credentials[\"api_secret\"]\n",
    "bearer_token = credentials[\"bearer_token\"]\n",
    "\n",
    "consumer_key = api_key\n",
    "consumer_secret = api_secret\n",
    "\n",
    "df_path = './tweets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65142cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_queries_en = [\n",
    "    \"We should stop subsidizing meat\",\n",
    "    \"We should subsidize green nutrition\",\n",
    "    \"We have to increase production of meat\",\n",
    "    \"We should exempt meat production from carbon taxes\",\n",
    "    \"We should add a carbon tax to food production\",\n",
    "    \"Meat alternatives should be encouraged\",\n",
    "    \"Plant based should be encouraged\",\n",
    "    \"Meat alternatives should be invested in\",\n",
    "    \"Plant based should be invested in\",\n",
    "    \"Meat alternatives should be subsidized\",\n",
    "    \"Plant based should be subsidized\",\n",
    "    \"We should introduce meatless mondays\",\n",
    "    \"Vegetarian and vegan diets should be encouraged\",\n",
    "    \"Vegetarian and vegan diets should be discouraged\",\n",
    "    \"We should subsidize fruits and vegetables\",\n",
    "    \"We should encourage more fruits and vegetable consumption\",\n",
    "    \"We should discourage fruits and vegetable consumption\",\n",
    "] \n",
    "\n",
    "tweet_queries_da = [\n",
    "    \"Vi bør stoppe med at subsidiere kød\",\n",
    "    \"Vi bør subsidiere grøn ernæring\",\n",
    "    \"Vi skal øge produktionen af kød\",\n",
    "    \"Vi bør fritage kød produktion fra co2 afgifter\",\n",
    "    \"Vi bør tilføje en co2 afgift til fødevare produktionen\",\n",
    "    \"Alternativer til kød bør fremmes og støttes\",\n",
    "    \"Plantebaseret bør fremmes og støttes\",\n",
    "    \"Der bør investeres i kødalternativer\",\n",
    "    \"Der bør investeres i plantebaseret\",\n",
    "    \"Alternativer til kød bør subsidieres\",\n",
    "    \"Plantebaseret bør subsidieres\",\n",
    "    \"Der bør opfordres til vegetarisk og vegansk kost\",\n",
    "    \"Vegetarisk og vegansk kost bør frarådes\",\n",
    "    \"Vi bør subsidiere frugt og grøntsager\",\n",
    "    \"Vi bør fremme forbruget af frugt og grøntsager\",\n",
    "    \"Vi bør fraråde forbrug af frugt og grøntsager\"\n",
    "]\n",
    "\n",
    "key_words_en = [\n",
    "    \"healthy food\",\n",
    "    \"food\",\n",
    "    \"green food\",\n",
    "    \"veganism\",\n",
    "    \"vegetable\",\n",
    "    \"good recipe\",\n",
    "    \"climate friendly recipe\",\n",
    "    \"climate friendly diet\",\n",
    "    \"healthy recipe\",\n",
    "    \"sustainable diet\",\n",
    "    \"green diet\",\n",
    "    \"diet with vegetable\",\n",
    "    \"vegetables are healthy\",\n",
    "    \"fruit and vegetable\",\n",
    "    \"fruit\",\n",
    "    \"vegetarian\",\n",
    "    \"vegan\",\n",
    "    \"good vegan recipe\",\n",
    "    \"good vegetarian recipe\",\n",
    "    \"organic\",\n",
    "    \"plant food is great\",\n",
    "    \"fresh and organic is good\",\n",
    "    \"varied and balanced diet\",\n",
    "    \"beans\",\n",
    "    \"sustainable meat\",\n",
    "    \"legumes\",\n",
    "    \"whole grains\",\n",
    "    \"local farmers market\",\n",
    "    \"plant based\",\n",
    "    \"meat alternative\",\n",
    "    \"plant based diet\",\n",
    "    \"green food is really good\",\n",
    "    \"animals are not ingredients\",\n",
    "    \"eat healthy food\",\n",
    "    \"raw food diet\",\n",
    "    \"whole foods\",\n",
    "    \"flexitarian\",\n",
    "    \"raw foodism\",\n",
    "    \"rawism\",\n",
    "]\n",
    "\n",
    "key_words_da = [\n",
    "    \"sund mad\",\n",
    "    \"mad\",\n",
    "    \"grøn mad\",\n",
    "    \"veganism\",\n",
    "    \"vegansk\",\n",
    "    \"vegetar\",\n",
    "    \"veganer\",\n",
    "    \"god opskrift\",\n",
    "    \"klima venlig opskrift\",\n",
    "    \"klima venlig kost\",\n",
    "    \"sund opskrift\",\n",
    "    \"grøntsags kost\",\n",
    "    \"frugt\",\n",
    "    \"frugt og grønt\",\n",
    "    \"god vegetarisk opskrift\",\n",
    "    \"god vegansk opskrift\",\n",
    "    \"økologisk\",\n",
    "    \"platebaseret er godt\",\n",
    "    \"frisk økologisk mad\",\n",
    "    \"bønner\",\n",
    "    \"bælgplanter\",\n",
    "    \"bælgfrugter\",\n",
    "    \"kød alternativer\",\n",
    "    \"dyr er ikke mad\",\n",
    "    \"fuldkost\",\n",
    "]\n",
    "\n",
    "filters = '-filter:retweets -filter:links -filter:quote -filter:videos' \n",
    "num_tweets_per_query = 1000\n",
    "min_tweet_length = 3\n",
    "token_mention = '<MENTION>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f029e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import itertools\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def generateQueries(queries, lang):\n",
    "    nQueries = []\n",
    "    stemmer = SnowballStemmer('english' if lang == 'en' else 'danish')\n",
    "    stops = set(stopwords.words('english' if lang == 'en' else 'danish'))\n",
    "    stops.update(['bør'])\n",
    "    for q in queries:\n",
    "        words = word_tokenize(q.lower())                        \n",
    "        meaningful_words = [w for w in words if not w in stops]   \n",
    "        words = ([stemmer.stem(w) for w in meaningful_words])\n",
    "        \n",
    "        for comb in itertools.combinations(meaningful_words, 2):\n",
    "            nQueries.append(' '.join(comb))\n",
    "        \n",
    "    return nQueries\n",
    "\n",
    "queries_da = [*generateQueries(tweet_queries_da, 'da'), *key_words_da]\n",
    "queries_en = [*generateQueries(tweet_queries_en, 'en'), *key_words_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa2f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tweets(api, queries, lang):    \n",
    "    tweet_dicts = []\n",
    "    \n",
    "    for query in queries:\n",
    "        print(\"=\"*100)\n",
    "        print('Scraping tweets for:', query)\n",
    "        res = tweepy.Cursor(api.search_tweets, q = query + ' ' + filters, lang = lang, count = num_tweets_per_query, tweet_mode = 'extended').items(num_tweets_per_query)\n",
    "        curLen = len(tweet_dicts)\n",
    "        for i, t in enumerate(res):\n",
    "            tweet_dicts.append({\n",
    "                \"tweet\": re.sub('@[^\\s]+', token_mention, t.full_text),\n",
    "                \"id\": t.id,\n",
    "                #\"topic\": topic,\n",
    "                \"lang\": t.lang,\n",
    "            })\n",
    "        print('Scraped',len(tweet_dicts) - curLen, 'tweets')\n",
    "        \n",
    "        # The 12 seconds could maybe be calculated depeding on number of queries\n",
    "        #sleep(12*(i+1-num_tweets_per_query)/num_tweets_per_query) # Sleep for 12 seconds, so that we don't do more than 180 request over 15 mins\n",
    "\n",
    "    return pd.DataFrame(tweet_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2531b04c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_da = scrape_tweets(api, queries_da, 'da')\n",
    "res_en = scrape_tweets(api, queries_en, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f2886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df = df.drop_duplicates(subset = ['tweet', 'id'])\n",
    "    df = df[df.tweet.str.split().str.len() > min_tweet_length]\n",
    "    return df\n",
    "\n",
    "res_da = clean_df(res_da)\n",
    "res_en = clean_df(res_en)\n",
    "res = pd.concat([res_da, res_en])\n",
    "res.to_csv('scraped_tweets_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac6c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3480909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "def pre(string, lang):\n",
    "    stemmer = SnowballStemmer('english' if lang == 'en' else 'danish')\n",
    "    stops = set(stopwords.words('english' if lang == 'en' else 'danish'))\n",
    "    \n",
    "    words = word_tokenize(re.sub('[^a-zA-Z]', ' ', string.lower().strip()))                        \n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    return ' '.join([stemmer.stem(w) for w in meaningful_words])\n",
    "\n",
    "\n",
    "def score(df):\n",
    "    df = df.copy()\n",
    "    for topic in df.topic.unique():\n",
    "        print('Calculating scores for:', topic)\n",
    "        lang = df[df.topic == topic].lang.values[0]\n",
    "        corpus = list(map(lambda x: pre(x, lang),df[df.topic == topic].tweet.values))\n",
    "\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_mtx = vectorizer.fit_transform(corpus)\n",
    "        topic_mtx = vectorizer.transform([pre(topic, lang)])\n",
    "        \n",
    "        cos_score = cosine_similarity(tfidf_mtx, topic_mtx)\n",
    "        \n",
    "        df.loc[df.topic == topic, ['score']] = cos_score\n",
    "    print('Done')\n",
    "    return df\n",
    "\n",
    "scored = score(res)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = scored.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d3817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for r in top.head(i+10).iloc[i:].iloc:\n",
    "    print('Topic:', r.topic, 'Tweet:', r.tweet)\n",
    "    print('='*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e86b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
